+++
date = "2016-02-17T22:22:16-08:00"
draft = false
title = "Boaz's Review of Books"
description = ""
tags = ["Literature","Books"]
Categories = ["Literature","Books"]
+++
A few books I recently finished reading are Ben Bernanke's [Courage to act]( http://www.nytimes.com/2015/10/25/books/review/ben-bernankes-the-courage-to-act.html ), Dr Philip Tetlock's [Superforecasting]( http://www.economist.com/news/books-and-arts/21666098-forecasting-talent-luckily-it-can-be-learned-unclouded-vision ),  Peter Thiel’s [Zero to One]( http://zerotoonebook.com/), an unofficial biography on George Soros, and collection of druggie short stories titled [Acid House](http://www.independent.co.uk/arts-entertainment/books/book-review-meeting-god-down-the-pub-the-acid-house-irvine-welsh-cape-pounds-999-1370403.html) by Irvine Welsh. I do not expect to do justice to the arguments in the books (read a real book review if you want that), I'm just sharing the lessons I learned from them as a little exercise.

Superforecasting is a persuasive essay by a well known academic, Dr Philip Tetlock, on how hard it is to make good decisions. The first half sets the ground by arguing that most "expert" predictions are either wrong or too vague to assess. There is an entire cottage industry of pundits and hacks built upon the fact that human beings crave certainty and simple narratives in an increasingly uncertain world. Unlike the authors, I don’t think this industry will ever disappear: we’ve still got horoscopes in the internet age. Humans are attracted to anecdotal evidence like we are to junk food:  it is appealing for evolutionary reasons, even if we know it shouldn’t be.

<center>
![a fun comic](http://smbc-comics.com/comics/20110626.gif)
</center>

Dr Tetlock then elaborates on decades of highly-interesting research on how to make more accurate predictions. I was surprised that this research was funded by the US intelligence community, which is a professional formation of experts the author has convincingly shown to be more-or-less useless. As an illustration, the book shares a scary anecdote from the days of the Cuban Missile Crisis, when security analysts were asked to judge the likelihood of a highly important outcome. They eventually agreed on writing a memo to the president which said the outcome was “probable”. Later, an outsider asked each analyst how they thought the word “probable” should be interpreted in terms of probability. Answers ranged from 0.3 (it is less likely to happen than not to happen) to 0.7 (it is more likely to happen than not to). We have no idea how Kennedy eventually interpreted it, but luckily we avoided nuclear annihilation. The book argues that forecasting as a profession is not unlike medicine before the arrival of double blind randomised trials. Lots of bloodletting, superstition and occasionally getting lucky. 

So how can we make more accurate predictions? The answer is unsurprising: through hard work. More specifically, it requires a painstaking research methodology coupled with an appropriate amount of numeracy. For instance, to determine the probability that Obama will successfully nominate a Supreme court judge now that Justice Scalia is dead, one would first examine potential outcomes (Obama nominates and accepted, Obama doesn't nominate, Obama nominates and isn't accepted), estimate the probability of each based on the base rate (how many nominee's get rejected out of all nominees) and adjust it based on new information. Once a prediction is made, one has to re-evaluate assumptions, auditing errors for both accurate and inaccurate predictions, checking up whether hypotheses are plausible in hindsight. This is very hard. How do you select the appropriate base rate? Is it all presidential nominees? Is it all presidential supreme court nominees? Or perhaps all presidential supreme court nominees nominated by presidents in their last year in office? This is of course a lot more boring than the experts you hear on television.

Importantly, even if something judged as likely to happen does not happen (or vice versa) it does not mean that the judgement was wrong. It’s unlikely you will win the lottery, yet someone has to win. The benefit of hindsight can lead us to make mistaken evaluations, Superforecasters need to learn to avoid them. Tolstoy playfully caricatured this tendency in War and Peace:

>“The profoundest and most excellent dispositions and orders seem very bad, and every learned militarist criticizes them with looks of importance, when they relate to a battle that has been lost, and the very worst dispositions and orders seem very good, and serious people fill whole volumes to demonstrate their merits, when they relate to a battle that has been won.”

In short, the methods offered by Dr Tetlock are not a panacea, which makes me instinctively less skeptical of his claims. The author admits that some things remain outright impossible: nobody is going to predict the outcome of the 2024 US presidential elections, but Nate Silver and his buddies might be able to tell us that this year’s most likely [won't be Donald Trump](http://fivethirtyeight.com/features/donald-trump-is-really-unpopular-with-general-election-voters/).

Peter Thiel is somewhat unimpressed by Mr Silver’s efforts in his book (more specifically, of society’s amazement with them), suggesting that the strenuous effort invested in predicting outcomes would be much better invested in trying to influence them. While Tetlock emphasises incremental improvements and careful calibration, Thiel believes true innovation comes from creating something entirely new, hence the title “From Zero to One”. Mr Thiel seems to believe that reality can be altered through the laborious efforts of clever and hardworking individuals, which is the sort of thing a billionaire funding libertarian [autonomous communities in international waters](http://theweek.com/articles/482427/libertarian-island-billionaires-utopia) would say. I’m less convinced of the objective truth of his assessment than of its usefulness as a personal philosophy. 

I seem to come across this sort of Orwellian “doublethink” phenomenon almost always when reading about successful individuals (termed the “reality distortion field” in the Steve Jobs’ biography): the ability to hold an unshakable, far-sighted conviction whilst staying sufficiently grounded in the reality to be able to alter it. What is remarkable is that this phenomenon holds for all sorts of realms, over a wide range of time spans. Max Weber calls it a balance between the “Ethics of Moral Conviction” and the “Ethics of Responsibility”, in *Politics as a Vocation*. Regardless whether he is right or wrong, Mr Thiel has undoubtedly done well for himself, perhaps precisely because he is wrong in the right way.

<center>
![funny chart](http://s3-ec.buzzfed.com/static/2014-03/enhanced/webdr05/26/14/enhanced-2984-1395857038-18.jpg)
</center>

That Mr Thiel, a serious capitalist, promotes "organic" monopolies is quite interesting. He believes that competition necessarily eats away at profits, and advises people to work on something that is ten times better, quicker or cheaper than what competitors are doing. In his ideal world, there are no resources wasted with airlines competing against each other, because some space hyper-loop company does transportation so much better than everyone else. According to Thiel’s recipe, you should establish a small monopoly through incredible innovation and aim to scale it, not unlike how Amazon started as an online bookstore and now is building an [army of drones](http://www.esquire.com/news-politics/news/a26138/amazon-drones/). It is clear he has Silicon Valley giants in mind, such as Facebook and Google, which hold a meritocratically obtained indisputable monopolies. However, while Facebook is the social network and Google is the search engine, aren’t they competing for the same clients in the online advertising industry? Isn’t scaling a small monopoly just another way to say incremental innovation? How was Facebook 10x better than MySpace? Had Mr Walton followed Thiel’s advice, would he have founded Walmart?

Perhaps the most valuable piece of advice I gleamed from both Thiel and Superforecasting was to appreciate the importance of a well-polished and deliberative methodology, and not to get disappointed by being wrong. This brings me to George Soros’ biography. This book has little in terms specifics on his investments, other than that George Soros can even make money selling unreadable books (the author doesn’t quite say it, but it is clear he thinks they are incomprehensible). However, Soros’ investment methodology includes elements that both Thiel and Tetlock would agree with: hypothesis testing, seeking out mistakes in thinking and going all in when necessary. As Soros said:

>It's not whether you're right or wrong, but how much money you make when you're right and how much you lose when you're wrong.

I found a lot more engaging Soros’ passion and influence on global politics through his philanthropy. Yet even here, the painful complexities of forecasting and subsequent decision-making are apparent. Two out of three of Hungary’s most important public servants, PM Orban and Speaker Kover received scholarships by Mr Soros’s Open Society Foundations when they were young. They are now both considered to be strongly anti-liberal and hostile to Soros. Is funding people who disagree with you consistent with the goals of Soros’ Open Society? Was 
Mr Soros wrong in funding them, or would saying so merely be making the same argument Tolstoy ridicules? 

On the subject of being wrong, there are few people for whom it is more expensive to be very wrong than the Chairman of the Federal Reserve. Ben Bernanke, former Chairman of the Fed (2006-2014), published a book last year mostly about how he was right. I particularly liked Bernanke's style, his writing exudes a calm and confidence of a central banker, almost (but not quite) to the point of making the hectic days of the crisis sound boring. As expected, he makes convincing arguments for his policies of bailouts and quantitative easing, making the interesting parallel:

>“You have a neighbor, who smokes in bed. . . . Suppose he sets fire to his house, you might say to yourself . . . ‘I’m not gonna call the fire department. Let his house burn down. It’s fine with me.’ But then, of course, what if your house is made of wood? And it’s right next door to his house? What if the whole town is made of wood?”

I am not well versed enough in economics to assess the merits and nuances of his argument, what I can assess is that many of the predictions which stem from these arguments don’t stack up to Superforecasting’s verifiability requirements: it is nearly impossible to know whether he was right or wrong. Partly this is because you cannot rewind time and try to do something different to see what happens but also because of their vagueness. For instance, notable critics of QE said it would cause runaway inflation in the US. It hasn’t happened yet, does that mean they were wrong? I am sure that if it happens within the next few years they’ll say “I told you so”, but even then we won’t know for certain. With a healthy dose of self-criticism, Bernanke quips:

>“Economists are criticized for not being able to predict the future, but, because the data are incomplete and subject to revision, we cannot even be sure what happened in the recent past.”

What is more interesting from my perspective is the role of the central banker in times of a panic. I can’t help but think it is very much like the role of a well-intentioned host in a drug party, reassuring people curled up in the corner on a LSD bad trip, giving some coke to help “sober up” to the drunk guys throwing up on the floor and telling the stoners trying to eat 10 liters of ice cream that it probably isn’t a good idea. The only difficulty is that the host isn’t quite sober himself, and any “treatment” he puts on the table is probably also going to be taken by someone who really shouldn’t. Meanwhile, his abusive parents are about to come home drunk from their own party, and they're going to be pissed off when they find out they have to pay for this mess. This allegory probably arises from the fact that I read Acid House concurrently. If you ever suffer from stressful days and sleep-less nights, as Bernanke did between 2007 and 2008, short stories of junkies will make you appreciate that there are many people who have it much worse than you do.

What our druggie analogy fails to capture is that the key element is that bubbles and panics develop not because the underlying fundamentals (whether people stop paying their morgages) shift radically, but because other what people think other people think. So? Well I’ll go out on a limb and make a prediction that it is more likely than not that a new crisis will emerge in the next two years. Of course, this prediction isn’t up to Superforcasting standards, it is simply based on the fact that they tend to happen every decade or so and I am reading more and more uneasy news. I'll leave more analytical financial predictions to the Soros types.


*By the way, the comics are from [SMBC.](http://smbc-comics.com/)*